# General Information

# Usage

## Installation
```bash
pip install -r requirements.txt
```

## Run Training Session
```bash
python carRacing.py MODEL_NAME ALGORITHM_NAME
```

## Run a trained model
```bash
python visualize.py MODEL_NAME ALGORITHM_NAME
# or
python visualize.py MODEL_NAME ALGORITHM_NAME SEED # to run a specific seed
```

## View statistics
```bash
python saves/stats.py CSV_FILE
```

# Implemented Reinforcement algorithms
| Algorithm |Â Description | File | Applicability | Implemented ? | Responsible |
| --- | --- | --- | --- | --- | --- |
| Classic Genetic Algorithm |Â  |Genetic.py |âœ… | âœ… | Gabriel |
| Deep Q Neural Network (DQN) |Â  |DQN.py |âœ… |ðŸ”§ | Nathan |
| Neat Algorithm |Â  |Â  |âœ… | ðŸš§ | Tom |
| DDPG Algorithm |Â  |Â  |âœ… |ðŸš§ | Gabriel |
| PPO Algorithm |Â  |Â  |âœ… |ðŸ”´ | Hugo |
| Actor Critic Method |Â  |Â  |âœ… |ðŸ”´ | Hugo |
| Q-learning or value-iteration methods |Â  |Â  |Â  |ðŸ”´ | |
| Q-Learning |Â  |Â  |Â  | ðŸ”´ | |

> https://en.wikipedia.org/wiki/Reinforcement_learning
> https://smartlabai.medium.com/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc
> https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-i-q-learning-sarsa-dqn-ddpg-72a5e0cb6287
> https://medium.datadriveninvestor.com/which-reinforcement-learning-rl-algorithm-to-use-where-when-and-in-what-scenario-e3e7617fb0b1

# Implemented models
| Model |Â Description | File | Implemented ? | Responsible |
| --- | --- | --- | --- | --- |
| CNN |Â  |CNN.py |âœ… | Nathan |
| Fully Connected |Â  |FullyConnected.py |âœ… | Gabriel |
| Selective CNN |Â  |SelectiveCNN.py |âœ… | Nathan |
| Selective Fully Connected + Kmeans | |SelectiveKMNN.py |âœ… | Nathan |

# Code architecture
```mermaid
flowchart TD
    A[Start] --> B[Load Brain and Estimator \nfrom entry arguments]
    B --> C{Save file\nexists ?}
    C --> |Yes| D[Load weights into brain]
    D --> E
    C --> |No| E[Loop of all simulations]
    E --> G[Simulation reset]
    G --> J[Current simulation loop]
    J --> K[Brain predicts next move]
    K --> L[Estimator memorizes current\nmove and state if needed]
    L --> M[Calculate current score\nfrom simulation]
    M --> N{Simulation\ndone ?}
    N --> |No| J
    N --> |Yes| O{New best\nscore ?}
    O --> |Yes| P[Save weights\nin file]
    O --> |No| Q
    P --> Q[Estimator updates brain's weights]
    Q --> R[Brain trains its network\nwith new weights]
    R --> E
```

# Research Papers
| Algorithm | Paper |
| --- | --- |
| Deep Q Neural Network (DQN) |Â https://medium.com/@cyberlympha/recurrent-neural-networks-in-reinforcement-learning-11600819ede4 |
| Deep Q Neural Network (DQN) |Â https://openreview.net/pdf?id=r1lyTjAqYX |
| Deep Q Neural Network (DQN) |Â https://towardsdatascience.com/deep-q-learning-tutorial-mindqn-2a4c855abffc |
| Deep Q Neural Network (DQN) |Â https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf |
| Deep Q Neural Network (DQN) |Â https://www.freecodecamp.org/news/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8 |
| Deep Q Neural Network (DQN) |Â https://keras.io/examples/rl/deep_q_network_breakout/ |
| Deep Q Neural Network (DQN) |Â https://github.com/keon/deep-q-learning/blob/master/dqn.py |
| Deep Q Neural Network (DQN) | https://huggingface.co/blog/deep-rl-dqn |
| Deep Q Neural Network (DQN) | https://huggingface.co/deep-rl-course/unit3/introduction |
| Deep Q Neural Network (DQN) | https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py |
| Deep Q Neural Network (DQN) | https://github.com/pekaalto/DQN |
